{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas\n",
    "\n",
    "import random\n",
    "import scipy.stats\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In the main text (see [**SUPLEMENTARY INFORMATION**](https://www.biorxiv.org/content/10.1101/2021.03.23.435334v1)), we show that the distribution of the time $t$ to see one among $N$ CTLs hitting the spheroid is exponentially distributed. Working backwards from there, we can infer the hitting rate $\\lambda_{in}$ and the leaving rate  $\\lambda_{out}$. Here we present how we extract the hitting rate from experimental data.\n",
    "\n",
    "Before running the analysis code please run the cells containing the utility functions that are the bottom of the page for greater clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "\n",
    "This script combines the different elements from the code below and conducts the bootstrapping procedure. It doesn't make any difference in the number of CTLs already on the spheroid but calculates the global hitting and leaving rates.\n",
    "\n",
    "The bootstrapping procedure works by choosing $N_{samples}$ among the total number of experiments (with discount REMISE), we estimate the lambdas, and we repeat the procedure $N_{tirages}$ times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the experimental dataframe containing the accumulation statistics `AnalysisFrame` we use the `bootstrap_scheme` function to get statistics on the hitting and leaving rates. In the cell below we extract the accumulation statistics for three independent experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnalysisFrame_OVA_20200804 = pandas.read_csv(os.path.join(r'accumulation_data/OVA', 'deadFrame_2min_20200804.csv'))\n",
    "AnalysisFrame_OVA_20201015 = pandas.read_csv(os.path.join(r'accumulation_data/OVA', 'deadFrame_2min_20201015.csv'))\n",
    "AnalysisFrame_OVA_20201113 = pandas.read_csv(os.path.join(r'accumulation_data/OVA', 'deadFrame_2min_20201113.csv'))\n",
    "\n",
    "AnalysisFrame = AnalysisFrame_OVA_20200804.append(AnalysisFrame_OVA_20201015).append(AnalysisFrame_OVA_20201113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = int(0.7*len(AnalysisFrame['ID'].unique()))\n",
    "n_tirages = 5\n",
    "\n",
    "bs_analysis = bootstrap_scheme(AnalysisFrame, \n",
    "                               n_samples, \n",
    "                               n_tirages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the accumulation acceleration\n",
    "\n",
    "We monitor here the differences in T-cell accumulation, but the model doesn't take into account the probability of coming into contact as a function of the number of T-cells already on the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the experimental dataframe containing the accumulation statistics `AnalysisFrame` we use the `lambda_per_n` function to get statistics on the hitting and leaving rates. On the same frame containing all the accumulation curves we conduct the estimation of $\\lambda$ for the different numbers of cells on the spheroid (up until `n_cells`).\n",
    "\n",
    "If the statistics are conducted on too few replicas (which can happen, especially for higher cell numbers), then the code returns a `np.Nan` to avoid computing faulty statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cells = 6\n",
    "n_samples = int(0.7*len(AnalysisFrame['ID'].unique()))\n",
    "n_repeats = 50\n",
    "\n",
    "lambda_per_n = lambda_per_contact_all(AnalysisFrame,\n",
    "                                      n_cells,\n",
    "                                      n_samples,\n",
    "                                      n_repeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "## Global bootstrapping procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics_single_well(single_well_frame):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Prepare the statistics table for a single well.\n",
    "\n",
    "    \n",
    "    '''\n",
    "        \n",
    "    single_well_frame['dN'] = single_well_frame['N contact'].shift(-1) - single_well_frame['N contact']\n",
    "    single_well_frame['dt'] = single_well_frame['time'].shift(-1) - single_well_frame['time']\n",
    "\n",
    "    return single_well_frame\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x.values, 0, 0)) \n",
    "    return ((cumsum[N:] - cumsum[:-N]) / float(N)).astype(int)\n",
    "\n",
    "def get_statistics(data_frame):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Prepare the statistics table.\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for ID in data_frame['ID'].unique():\n",
    "        \n",
    "        loc_frame = data_frame[data_frame['ID'] == ID]\n",
    "        stat_frame = get_statistics_single_well(loc_frame)\n",
    "        data_frame.loc[data_frame['ID'] == ID, 'dN'] = stat_frame['dN']\n",
    "        data_frame.loc[data_frame['ID'] == ID, 'dt'] = stat_frame['dt']\n",
    "        data_frame.loc[data_frame['ID'] == ID, 'N'] = stat_frame['N'].max()\n",
    "        data_frame.loc[data_frame['ID'] == ID, 'N gel'] = stat_frame['N'].max() - loc_frame['N contact']\n",
    "        \n",
    "    return data_frame[['ID', 'frame', 'time', 'N', 'N contact', 'N gel', 'dN', 'dt']]\n",
    "\n",
    "\n",
    "\n",
    "def get_probability_arrival(AnalysisFrame):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Calculate the probability of hitting the spheroid as a function\n",
    "    of the number of CTLs in the gel.\n",
    "    \n",
    "    Enter:\n",
    "     - AnalysisFrame: pandas.Dataframe\n",
    "     \n",
    "     Returns:\n",
    "      - properties: pandas.DataFrame object where each line corresponds\n",
    "        to a given number of CTLs.\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    stats_frame = get_statistics(AnalysisFrame)\n",
    "    stats_frame = stats_frame.dropna()\n",
    "\n",
    "    stats_frame['ID_time'] = stats_frame['ID'] + ' : ' + stats_frame['frame'].astype(int).astype(str)\n",
    "\n",
    "    stats_frame_arrival = stats_frame.copy()\n",
    "    stats_frame_arrival.loc[stats_frame['dN'] < 0, 'dN'] = 0\n",
    "    \n",
    "    probs_arrival = stats_frame_arrival.pivot(index = 'ID_time', columns = 'N gel', values = 'dN').mean(axis = 0)\n",
    "    counts_arrival = stats_frame_arrival.pivot(index = 'ID_time', columns = 'N gel', values = 'dN').count(axis = 0)\n",
    "\n",
    "    properties = pandas.concat([probs_arrival, counts_arrival], axis = 1)\n",
    "    properties.columns = ['probability', 'counts']\n",
    "    \n",
    "    return properties\n",
    "\n",
    "def get_lambda_arrival(prob_arrive, \n",
    "                       minN = 0, \n",
    "                       maxN = 20):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    From the probability to hit the spheroid infer lambda_arrival.\n",
    "    \n",
    "    Enter:\n",
    "     - prob_arrive: pandas.Dataframe\n",
    "     \n",
    "     Returns:\n",
    "      - lambda_in:float\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    prob_arrive = prob_arrive[minN:maxN]\n",
    "    \n",
    "    value_list = [value for value in (-np.log(1 - prob_arrive['probability'])/prob_arrive.index).values if ~np.isnan(value)]\n",
    "    bool_list = [~np.isnan(value) for value in (-np.log(1 - prob_arrive['probability'])/prob_arrive.index).values]\n",
    "    \n",
    "    # we require a minimum number of counts to assure the statistical\n",
    "    # validity of the estimated figure.\n",
    "    \n",
    "    if np.sum(prob_arrive['counts'].values[bool_list]) > 25:\n",
    "    \n",
    "        return np.average(value_list, \n",
    "                      weights = prob_arrive['counts'].values[bool_list])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        return np.nan\n",
    "\n",
    "def get_probability_leave(AnalysisFrame):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Calculate the probability of hitting the spheroid as a function\n",
    "    of the number of CTLs on the spheroid.\n",
    "    \n",
    "    Enter:\n",
    "     - AnalysisFrame: pandas.Dataframe\n",
    "     \n",
    "     Returns:\n",
    "      - properties: pandas.DataFrame object where each line corresponds\n",
    "        to a given number of CTLs.\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    stats_frame = get_statistics(AnalysisFrame)\n",
    "    stats_frame = stats_frame.dropna()\n",
    "\n",
    "    stats_frame['ID_time'] = stats_frame['ID'] + ' : ' + stats_frame['frame'].astype(int).astype(str)\n",
    "\n",
    "    stats_frame_leave = stats_frame\n",
    "    stats_frame_leave.loc[stats_frame['dN'] > 0, 'dN'] = 0\n",
    "\n",
    "    probs_leave = np.abs(stats_frame_leave.pivot(index = 'ID_time', columns = 'N contact', values = 'dN').mean(axis = 0))\n",
    "    counts_leave = stats_frame_leave.pivot(index = 'ID_time', columns = 'N contact', values = 'dN').count(axis = 0)\n",
    "\n",
    "    properties = pandas.concat([probs_leave, counts_leave], axis = 1)\n",
    "    properties.columns = ['probability', 'counts']\n",
    "                \n",
    "    return properties\n",
    "\n",
    "def get_lambda_leave(prob_leave, minN = 0, maxN = 20):\n",
    "    \n",
    "    prob_leave = prob_leave[minN:maxN]\n",
    "    prob_leave = prob_leave[prob_leave['probability'] < 1]\n",
    "    prob_leave = prob_leave[prob_leave.index > 0]\n",
    "    \n",
    "    if prob_leave.empty:\n",
    "        \n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "                \n",
    "        return np.average((-np.log(1 - prob_leave['probability'])/prob_leave.index).values, \n",
    "                      weights = prob_leave['counts'].values)\n",
    "\n",
    "def bootstrap_scheme(AnalysisFrame, N_samples, N_tirages):\n",
    "    \n",
    "    bootstrap_data = pandas.DataFrame()\n",
    "    j = 0\n",
    "    k = 0\n",
    "    \n",
    "    for i in range(N_tirages):            \n",
    "    \n",
    "        experiments = np.random.choice(list(AnalysisFrame['ID'].unique()), N_samples, replace = True)\n",
    "                \n",
    "        loc_analysis = pandas.DataFrame()\n",
    "        \n",
    "        for ID in experiments:\n",
    "            loc_frame = AnalysisFrame[AnalysisFrame['ID'] == ID]\n",
    "            loc_frame['ID'] = loc_frame['ID'] + ' : ' + str(j)\n",
    "            j += 1\n",
    "            loc_analysis = loc_analysis.append(loc_frame)\n",
    "                        \n",
    "        probabilities = get_probability_arrival(loc_analysis)\n",
    "        bootstrap_data.loc[j, 'lambda_arrival'] = get_lambda_arrival(probabilities)\n",
    "        \n",
    "        if math.isnan(get_lambda_arrival(probabilities)):\n",
    "                                \n",
    "            probabilities = get_probability_leave(loc_analysis)\n",
    "        \n",
    "        if probabilities.empty:\n",
    "            \n",
    "            bootstrap_data.loc[j, 'lambda_leave'] = np.nan\n",
    "            j += 1\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            bootstrap_data.loc[j, 'lambda_leave'] = get_lambda_leave(probabilities)\n",
    "            j += 1\n",
    "        \n",
    "    return bootstrap_data\n",
    "    \n",
    "def get_max_N(AnalysisFrame):\n",
    "    \n",
    "    for ID in tqdm(AnalysisFrame['ID'].unique()):\n",
    "        \n",
    "        AnalysisFrame.loc[AnalysisFrame['ID'] == ID, 'N'] = AnalysisFrame.loc[AnalysisFrame['ID'] == ID, 'N'].max()\n",
    "        \n",
    "    return AnalysisFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiating per CTL on the spheroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correcting for the low sample number in the WT case\n",
    "\n",
    "def get_lambda_arrival(prob_arrive, minN = 0, maxN = 20):\n",
    "        \n",
    "    prob_arrive = prob_arrive[minN:maxN]\n",
    "    \n",
    "    value_list = [value for value in (-np.log(1 - prob_arrive['probability'])/prob_arrive.index).values if ~np.isnan(value)]\n",
    "    bool_list = [~np.isnan(value) for value in (-np.log(1 - prob_arrive['probability'])/prob_arrive.index).values]\n",
    "    \n",
    "    if np.sum(prob_arrive['counts'].values[bool_list]) > 100:\n",
    "    \n",
    "        return np.average(value_list, \n",
    "                      weights = prob_arrive['counts'].values[bool_list])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        return np.nan\n",
    "\n",
    "def get_lambda_leave(prob_leave, minN = 0, maxN = 20):\n",
    "    \n",
    "    prob_leave = prob_leave[minN:maxN]\n",
    "    prob_leave = prob_leave[prob_leave['probability'] < 1]\n",
    "    prob_leave = prob_leave[prob_leave.index > 0]\n",
    "    \n",
    "    if prob_leave.empty:\n",
    "        \n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "                \n",
    "        return np.average((-np.log(1 - prob_leave['probability'])/prob_leave.index).values, \n",
    "                      weights = prob_leave['counts'].values)\n",
    "\n",
    "def get_statistics(data_frame):\n",
    "    \n",
    "    for ID in data_frame['ID'].unique():\n",
    "        \n",
    "        loc_frame = data_frame[data_frame['ID'] == ID]\n",
    "        \n",
    "        stat_frame = get_statistics_single_well(loc_frame)\n",
    "        \n",
    "        data_frame.loc[data_frame['ID'] == ID, 'dN'] = stat_frame['dN']\n",
    "        data_frame.loc[data_frame['ID'] == ID, 'dt'] = stat_frame['dt']\n",
    "        data_frame.loc[data_frame['ID'] == ID, 'N'] = stat_frame['N'].max()\n",
    "        data_frame.loc[data_frame['ID'] == ID, 'N gel'] = stat_frame['N'].max() - loc_frame['N contact']\n",
    "            \n",
    "    return data_frame[['ID', 'frame', 'time', 'N', 'N contact', 'N gel', 'dN', 'dt']]\n",
    "\n",
    "def get_probability_arrival_contact(AnalysisFrame, N_contact):\n",
    "    \n",
    "    stats_frame = get_statistics(AnalysisFrame)\n",
    "    stats_frame = stats_frame[stats_frame['N contact'] == N_contact]\n",
    "    stats_frame = stats_frame.dropna()\n",
    "\n",
    "    stats_frame['ID_time'] = stats_frame['ID'] + ' : ' + stats_frame['frame'].astype(int).astype(str)\n",
    "\n",
    "    stats_frame_arrival = stats_frame\n",
    "    stats_frame_arrival.loc[stats_frame['dN'] < 0, 'dN'] = 0\n",
    "\n",
    "    # remove cases where the number change is beyond 1\n",
    "    stats_frame_arrival = stats_frame_arrival.drop(stats_frame_arrival[stats_frame_arrival['dN'] > 1].index)\n",
    "\n",
    "    probs_arrival = stats_frame_arrival.pivot(index = 'ID_time', columns = 'N gel', values = 'dN').mean(axis = 0)\n",
    "    counts_arrival = stats_frame_arrival.pivot(index = 'ID_time', columns = 'N gel', values = 'dN').count(axis = 0)\n",
    "        \n",
    "    stats_frame_arrival['Date'] = stats_frame_arrival['ID'].str.split(' : ', expand = True)[0]\n",
    "    stats_frame_arrival['m'] = stats_frame_arrival['ID'].str.split(' : ', expand = True)[1]\n",
    "    \n",
    "    stats_frame_arrival['ID_well'] = stats_frame_arrival['Date'] + ' : ' + stats_frame_arrival['m']\n",
    "    \n",
    "    if (len(stats_frame_arrival['ID_well'].unique()) < 10):\n",
    "\n",
    "        properties = pandas.DataFrame(data = [[np.nan, np.nan]])\n",
    "        properties.columns = ['probability', 'counts']        \n",
    "        \n",
    "        return properties\n",
    "    \n",
    "\n",
    "    properties = pandas.concat([probs_arrival, counts_arrival], axis = 1)\n",
    "    properties.columns = ['probability', 'counts']\n",
    "    \n",
    "    return properties\n",
    "\n",
    "def get_probability_leave_contact(AnalysisFrame, N_contact):\n",
    "    \n",
    "    stats_frame = get_statistics(AnalysisFrame)\n",
    "    stats_frame = stats_frame[stats_frame['N contact'] == N_contact]\n",
    "    stats_frame = stats_frame.dropna()\n",
    "\n",
    "    stats_frame['ID_time'] = stats_frame['ID'] + ' : ' + stats_frame['frame'].astype(int).astype(str)\n",
    "\n",
    "    stats_frame_leave = stats_frame\n",
    "    stats_frame_leave.loc[stats_frame['dN'] > 0, 'dN'] = 0\n",
    "\n",
    "    # remove cases where the number change is beyond 1\n",
    "    stats_frame_leave = stats_frame_leave.drop(stats_frame_leave[stats_frame_leave['dN'] < -1].index)\n",
    "\n",
    "    probs_leave = np.abs(stats_frame_leave.pivot(index = 'ID_time', columns = 'N contact', values = 'dN').mean(axis = 0))\n",
    "    counts_leave = stats_frame_leave.pivot(index = 'ID_time', columns = 'N contact', values = 'dN').count(axis = 0)\n",
    "\n",
    "    \n",
    "    if len(stats_frame_leave)>0:\n",
    "        \n",
    "        stats_frame_leave['Date'] = stats_frame_leave['ID'].str.split(' : ', expand = True)[0]\n",
    "        stats_frame_leave['m'] = stats_frame_leave['ID'].str.split(' : ', expand = True)[1]\n",
    "\n",
    "        stats_frame_leave['ID_well'] = stats_frame_leave['Date'] + ' : ' + stats_frame_leave['m']\n",
    "    \n",
    "        if len(stats_frame_leave['ID_well'].unique()) < 6:\n",
    "\n",
    "            properties = pandas.DataFrame(data = [[np.nan, np.nan]])\n",
    "            properties.columns = ['probability', 'counts']        \n",
    "\n",
    "            return properties\n",
    "    \n",
    "        properties = pandas.concat([probs_leave, counts_leave], axis = 1)\n",
    "        properties.columns = ['probability', 'counts']\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        properties = pandas.DataFrame(data = [[np.nan, np.nan]])\n",
    "        properties.columns = ['probability', 'counts']  \n",
    "\n",
    "    \n",
    "    return properties\n",
    "\n",
    "def bootstrap_scheme_per_n(AnalysisFrame, N_samples, N_tirages, N_contact):\n",
    "    \n",
    "    bootstrap_data = pandas.DataFrame()\n",
    "    j = 0\n",
    "    k = 0\n",
    "    \n",
    "    for i in range(N_tirages):            \n",
    "    \n",
    "        experiments = np.random.choice(list(AnalysisFrame['ID'].unique()), N_samples)\n",
    "                \n",
    "        loc_analysis = pandas.DataFrame()\n",
    "        \n",
    "        for ID in experiments:\n",
    "            loc_frame = AnalysisFrame[AnalysisFrame['ID'] == ID]\n",
    "            loc_frame['ID'] = loc_frame['ID'] + ' : ' + str(j)\n",
    "            j += 1\n",
    "            loc_analysis = loc_analysis.append(loc_frame)\n",
    "                                    \n",
    "        probabilities = get_probability_arrival_contact(loc_analysis, N_contact)\n",
    "                \n",
    "        try:\n",
    "            bootstrap_data.loc[j, 'lambda_arrival'] = get_lambda_arrival(probabilities)\n",
    "        except:\n",
    "            bootstrap_data.loc[j, 'lambda_arrival'] = np.nan\n",
    "        \n",
    "        probabilities = get_probability_leave_contact(loc_analysis, N_contact)\n",
    "        \n",
    "        try:\n",
    "            bootstrap_data.loc[j, 'lambda_leave'] = get_lambda_leave(probabilities)\n",
    "        except:\n",
    "            bootstrap_data.loc[j, 'lambda_leave'] = np.nan\n",
    "        j += 1\n",
    "        \n",
    "    return bootstrap_data\n",
    "\n",
    "def lambda_per_contact_all(AnalysisFrame, N_contact_max,  N_samples, N_tirages):\n",
    "    \n",
    "    lambda_data = pandas.DataFrame()\n",
    "    \n",
    "    for N_contact in tqdm(range(N_contact_max)):\n",
    "                        \n",
    "        bs_stats = bootstrap_scheme_per_n(AnalysisFrame, N_samples, N_tirages, N_contact)\n",
    "                \n",
    "        bs_stats['N_contact'] = N_contact\n",
    "                \n",
    "        lambda_data = lambda_data.append(bs_stats)\n",
    "                \n",
    "    return lambda_data\n",
    "\n",
    "def get_max_N(AnalysisFrame):\n",
    "    \n",
    "    for ID in tqdm(AnalysisFrame['ID'].unique()):\n",
    "        \n",
    "        AnalysisFrame.loc[AnalysisFrame['ID'] == ID, 'N'] = AnalysisFrame.loc[AnalysisFrame['ID'] == ID, 'N'].max()\n",
    "        \n",
    "    return AnalysisFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
